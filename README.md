# Model Poisoning in Multi-Class Algorithms

## Overview

This project explores the concept of **Model Poisoning** in multi-class classification algorithms. Model poisoning refers to the intentional manipulation or corruption of the training data to degrade the performance of a machine learning model. In the context of multi-class algorithms, this type of attack can affect models that classify data into multiple categories, potentially introducing vulnerabilities and biases.
